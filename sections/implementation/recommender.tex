\section{Recommender system}\label{Recommender-system}
It would be beneficial to provide a way for users to see relevant, interesting services for their preferences, in order to make the system more usable.
To accomplish this, a recommender system can be used.
The following section will detail different ways of implementing such a system, which one we chose and why, and finally our implementation of a recommender system.

\subsection{The purpose of a recommender system}
When searching for something new, information overload can occur.
Many different sources can provide information that might not be relevant.
If a new user interacts with this system, seeking to find a new subject in which to attain knowledge, this user could potentially be presented with an overwhelming amount of services, depending on how many tutors have made these available.
Another issue that might arise is that not all of the services will be relevant for the new user, serving only to clog the list of services. 
This leads to information overload, where the retrieved information in the form of services is not what the user needs, and not enough of the correctly relevant information is returned.
Recommender systems are used to remedy these issues.
They help match users with relevant items, in this case services, to ease the information overload.
This generates value for both the user and the tutor, in that users are matched with what they have a predilection for, and tutors can reach more prospective students.
We discuss two methods of creating a recommender, \textit{content-based filtering} and \textit{collaborative filtering}.

\subsection{Content-based filtering}\label{content-based-filtering}
Content-based recommender systems recommend an item to a user based upon a description of the item and a profile of the user's interests \cite{ContentBasedFiltering}.
A common scenario for web applications is that they present a list of items to a user, and the user then selects among these to receive more details. 
An item in such a scenario would have a representation dependent on the implementation, which could be used to analyze items of particular interest for a user.
Items are often stored in databases, creating structured data with each entry having the same set of attributes. 
This lends itself well to learning a user profile through different machine learning algorithms.
Examples of a basic representation of items and users are shown in Figures \ref{tbl:content-item} and \ref{tbl:content-user}.
\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|l|l|l|}
    \hline
    Title                                         & Genre    & Author        & Price & Type      \\ \hline
    Blue Moon                                     & Thriller & Lee Child     & 10    & Hardcover \\ \hline
    Norse Mythology                               & Fantasy  & Neil Gaiman   & 6     & Paperback \\ \hline
    Normandy ‘44: D-Day and the Battle for France & History  & James Holland & 14    & Hardcover \\ \hline
    \end{tabular}
    \caption{This figure shows a possible representation of a few items for content-based filtering.}
    \label{tbl:content-item}
    \end{table}
\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|l|l|l|}
    \hline
    Title                                         & Genre    & Author        & Price & Type      \\ \hline
    ... & Fantasy  & George R. R. Martin, J.K. Rowling & 5    & Paperback \\\hline
    \end{tabular}
    \caption{This figure shows a possible representation of a user.}
    \label{tbl:content-user}
\end{table}
\noindent
The basic idea for content-based filtering is then to compute the similarity of an unseen item with the user profile, and suggest the most similar items.
Unstructured data, such as text fields with no restriction, create complications when creating a user profile, as relationships between the values on an attribute for different items for a specific user can be found, but an unrestricted text will generally be unique \cite{ContentBasedFiltering}. 
If a user liked different restaurants based on the same cuisine, it could be indicated that this user would be likely to like other restaurants focused in the same cuisine as well, but a text review would not necessarily give this information.
Many domains can be represented by semi-structured data where issues such as text fields are converted to a structured representation \cite{ContentBasedFiltering}.
A user profile shows the preferences of the user, and consists mainly of two types of information:
\begin{itemize}
    \item A description of the types of items that interest the user
    \item A history of the user's interactions with the recommender system, such as storing the items that a user has viewed and information related to the interaction, such as if the user purchased the item.
\end{itemize}
Historical data of interactions can be used to filter out already purchased items, display recently visited items or as training data.
Creating a model of a user's preferences is then done through a form of classification learning, in which training data is divided into categories, an example being the binary categories \textit{Items the user likes} and \textit{items the user dislikes} \cite{ContentBasedFiltering}.
These algorithms learn a function that model's a users interests, and given a new item and the user model, this function predicts whether or not the user is interested in the item through a probability or a numeric value by analyzing the item representation and user profile.
Popular learning approaches for content-based filtering are \textit{naïve Bayes}, \textit{nearest neighbor methods} or \textit{linear classifiers}.

\subsection{Collaborative filtering}
Collaborative filtering differs from content-based filtering in that it focuses on matching users and items through the opinions of other people.
Collaborative filtering is based on word-of-mouth recommendations.
A person might have friends that recommend different things, and will eventually learn which of these friends has tastes that most align with their own, and thus which recommendation to value the most.
Collaborative filtering extends this concept \cite{CollaborativeFiltering}.
Collaborative filtering makes use of ratings.
These could be ratings between 1-5 or 1-10, for example, or simply binary ratings.
A rating is an association of two things, a user and a value.
A matrix of ratings can then be constructed, as shown in \autoref{tbl:collaborative-example}.
The empty entries indicate that the user has not rated the item, and are what the system should be able to predict.
\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|l|l|l|}
    \hline
           & Item1 & Item2 & Item3 & Item4 \\ \hline
    Peter  & 3     &       & 5     &       \\ \hline
    Amy    & 4     & 2     &       & 3     \\ \hline
    Lars   &       & 5     & 3     & 2     \\ \hline
    Martin & 1     &       & 2     & 4     \\ \hline
    \end{tabular}
    \caption{This figure shows an example of a ratings matrix, with ratings from 1 to 5. An empty entry indicates that the user has not rated the item.}
    \label{tbl:collaborative-example}
\end{table}
\noindent
Domains with certain properties lend themselves to collaborative filtering. 
These are \textit{data distribution}, \textit{underlying meaning} and \textit{data persistence} \cite{CollaborativeFiltering}.
Data distribution encompasses domains in which there are many items, many ratings per item, more users rating that items to be recommended and users rate multiple items.
Underlying meaning encompasses domains in which users can have tastes in common, evaluation of an item cannot be done objectively and items are homogenous.
Data persistence encompasses domains in which items persist and taste persists, meaning the tastes of the users do not change rapidly.
Collaborative filtering usually makes use of \texttt{k nearest neighbor} algorithms based on users or items, or latent factor models to create predictions.
The user-based nearest neighbor approach focuses on finding users with similar tastes from which to predict a given user's rating, whereas the item-based approach focuses on finding items similar to a given item, and then taking the user's ratings for those similar items to predict a rating for an unrated item.
The latent factor approach focuses on splitting the rating matrix into separate matrices through matrix factorization to simulate communities, and creating predictions from these.


\subsection{Pros and cons}


\subsection{Description of collaborative filtering through matrix factorization more in depth}

\subsection{Our implementation}
In \autoref{lst:recomstart} we initially make use of our other services to get the required data to predict ratings.
To perform the calculations we need all users, all services and all ratings currently in the database.
We then initialize the necessary matrices by making all their entries 0, and for the ratings matrix we call a function to populate it.
This is done by traversing the matrix, and for each rating in the \texttt{allRatings} variable, we search the ratings matrix for ids corresponding to the service and user ids of that rating.
If found, we insert the rating value into that entry.
\begin{lstlisting}[caption={The start of the recommender}, captionpos=b, label={lst:recomstart}]
    export default class Recommender {
        static async calculateRecommendations(): Promise<number[][]> {
            const allUsers = await UserService.getAll();
            const allServices = await ServiceService.getAll();
            const allRatings = await RatingService.getAll();
    
            let userServiceMatrix: number[][] = [];
            let predictedRatings: number[][] = [];
            let userFactorMatrix: number[][] = [];
            let serviceFactorMatrix: number[][] = [];

            userServiceMatrix = initUserServiceMatrix(numberOfRows, numberOfCols, allUsers, allServices, userServiceMatrix);

		    userServiceMatrix = populateUserServiceMatrix(allRatings, numberOfRows, numberOfCols, userServiceMatrix);
            \dots
\end{lstlisting}
When we initialize both the matrix for users and factors as well as the matrix for services and factors we initialize all entries with random values between 0 and 1.
This is done to ensure we can calculate a predicted rating.
The actual value is arbitrary, but a small value is chosen, as this should make the algorithm arrive at a model faster, compared to initializing with a greater value.
\begin{lstlisting}[caption={Initializing the user and factor matrix}, captionpos=b, label={lst:initUserFactor}]
    function initUserFactorMatrix(numberOfRows: number, numberOfFactors: number, userFactorMatrix: number[][]): number[][] {
        for (let i = 0; i < numberOfRows; i++) {
            userFactorMatrix[i] = []; // Initialize inner array
            for (let j = 0; j < numberOfFactors; j++) {
                userFactorMatrix[i][j] = Math.random() * 1;
            }
        }
    
        return userFactorMatrix;
    }
\end{lstlisting}
After initializing the different matrices, we start out first calculation of predictions.
To do so, we call a function to calculate the dot products of the user by factor and factor by service matrices.
It simply iterates over a row from one matrix and a column for the other, multiplying the corresponding entries of each matrix, and adding them together.
The sum is then inserted into the predictedRatings matrix.
\begin{lstlisting}[caption={}, captionpos=b, label={}]
    function dotMatrices(
        numberOfRows: number,
        numberOfCols: number,
        numberOfFactors: number,
        userFactorMatrix: number[][],
        serviceFactorMatrix: number[][],
    ): number[][] {
        const predictedRatings: number[][] = [];
        let sum = 0;
        for (let i = 0; i < numberOfRows; i++) {
            predictedRatings[i] = [];
            for (let j = 0; j < numberOfCols; j++) {
                for (let k = 0; k < numberOfFactors; k++) {
                    sum = sum + userFactorMatrix[i][k] * serviceFactorMatrix[k][j];
                }
                predictedRatings[i][j] = sum;
                sum = 0;
            }
        } 
        return predictedRatings;
    }
\end{lstlisting}
After calculating the predicted ratings, we need to determine the error and update the values of the factor matrices.
To calculate the error, we use the equation defined in \autoref{fig:calculatingerror}, which simply subtracts the predicted value from the actual value.
We then use the updating rules defined in the equations in Figures \ref{fig:updatingq} and \ref{fig:updatingp} to update the values of the matrices.
We define the $\gamma$ value from the equation as the \texttt{alphaValue}, the $\lambda$ value as \texttt{0.001} and assign them to be 0.001, based on testing and recommended values.

\begin{lstlisting}[caption={}, captionpos=b, label={}]
    const alphaValue = 0.001;
    const betaValue = 0.001;
    for (let i = 0; i < numberOfRows; i++) {
        for (let j = 0; j < numberOfCols; j++) {
            if (userServiceMatrix[i + 1][j + 1] > 0) {
                const error = userServiceMatrix[i + 1][j + 1] - predictedRatings[i][j];
                for (let k = 0; k < numberOfFactors; k++) {
                    userFactorMatrix[i][k] =
                        userFactorMatrix[i][k] +
                        alphaValue * (error * serviceFactorMatrix[k][j] - betaValue * userFactorMatrix[i][k]);
                    serviceFactorMatrix[k][j] =
                        serviceFactorMatrix[k][j] +
                        alphaValue * (error * userFactorMatrix[i][k] - betaValue * serviceFactorMatrix[k][j]);
                }
            }
        }
    }
    \dots
\end{lstlisting}
After updating the values, we calculate the dot product of the two factor matrices again, and use the new predictions to calculate the squared error.
The squared error is calculated with the equation defined in \autoref{fig:minimizesquarederror}.
We initially look at the matrix containing our actual ratings.
We traverse it, and when the value of an entry is greater than 0, we know there is a rating.
We subtract the prediction from the actual rating and square it, and then for the number of factors we add the regularization by squaring the values from both factor matrices, and multiplying it with the $\lambda$ value.
\begin{lstlisting}[caption={}, captionpos=b, label={}]
    let squareError = 0;
    for (let i = 0; i < numberOfRows; i++) {
        for (let j = 0; j < numberOfCols; j++) {
            if (userServiceMatrix[i + 1][j + 1] > 0) {
                squareError =
                    squareError + Math.pow(userServiceMatrix[i + 1][j + 1] - predictedRatings[i][j], 2);
                for (let k = 0; k < numberOfFactors; k++) {
                    squareError =
                        squareError +
                        betaValue *
                            (Math.pow(userFactorMatrix[i][k], 2) + Math.pow(serviceFactorMatrix[k][j], 2));
                }
            }
        }
    }
    \dots
\end{lstlisting}
Once the algorithm completes, we need to make our data persist.
To do this, we keep a separate ratings table in the database consisting of predicted ratings.
To send the calculated ratings, we add them to the user by service matrix.
Since we want to avoid possibly recommending a service the user has already rated, whenever we encounter an entry that is not 0, we remove that rating and assign it to be 0 instead.
This means that, even if a user rated a service with the maximum value, they will not get it as a recommendation since it will now rank in the bottom with a rating of 0.
The user by service matrix is then ready to be inserted into the database.
\begin{lstlisting}[caption={}, captionpos=b, label={}]
    for (let i = 0; i < numberOfRows; i++) {
        for (let j = 0; j < numberOfCols; j++) {
            if (userServiceMatrix[i + 1][j + 1] == 0) {
                userServiceMatrix[i + 1][j + 1] = predictedRatings[i][j];
            } else {
                userServiceMatrix[i + 1][j + 1] = 0;
            }
        }
    }
    \dots
\end{lstlisting}
